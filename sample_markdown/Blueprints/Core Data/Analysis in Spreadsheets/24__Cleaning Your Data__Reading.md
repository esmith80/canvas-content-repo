

![clean](https://media.giphy.com/media/2tSk579HlpT7n8VOY9/giphy.gif)

Picture this, you've just spent the last few weeks analyzing some data, you're presenting to your boss and **BOOM** she notices something that doesn't quite feel right, what you've discovered doesn't match her understanding of the subject matter. You might think this is a bad thing, but what if instead your findings were taken as the be all end all **truth** and your team ended up making a big decision based on them? 

What likely happened here, is the data you were working with was _dirty_ and you may have forgotten to clean it up! The thing about dirty data - is it often leads to false conclusions. A good way to think of it is **garbage in = garbage out.**

## The Workflow

[This article](https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4) outlines a simple workflow for data cleaning. We recommend reading the whole article, when you have time, but for now, here is a summary of that workflow:

1. **Inspection:** Detect unexpected, incorrect, and inconsistent data.
2. **Cleaning:** Fix or remove the anomalies discovered.
3. **Verifying:** After cleaning, the results are inspected to verify correctness.
4. **Reporting:** A report about the changes made and the quality of the currently stored data is recorded.

