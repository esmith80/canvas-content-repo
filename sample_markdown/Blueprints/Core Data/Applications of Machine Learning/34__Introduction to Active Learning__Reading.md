---
uuid: 0309356c-fd88-4df6-bd29-a87cf5f9e878
duration: 20
---

We will now take a closer look at one of the learning techniques we saw in the previous reading – `Active Learning`.


## Introduction to Active Learning

Previously, we went through an article saying that our models can be only as good as our training data. This is absolutely true so, in many cases, getting properly labeled data is the most expensive step (with the cost not being necessarily measured in $$$ but also time or any other resource).

This is the motivation behind **Active Learning**, where the main idea is that a learning algorithm can choose the data it wants to learn from and can achieve similar results with substantially smaller training samples.


> #### Instruction
> Read about the basics of *Active Learning* in the article [**Active Learning: Curious AI Algorithms**](https://www.datacamp.com/community/tutorials/active-learning).


## Conclusion

We have seen how *Active Learning* tries to select the best observations to learn from. The cool thing is that this is not limited to advanced algorithms like Neural Networks or Boosting algorithms – we can use a similar approach with traditional linear regression, as well.
